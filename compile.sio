var TokenKind = Enum("TokenKind", "IF THEN ELSE IDENT INT OPERATOR PRINT STRING VAR ASSIGN UNKNOWN EOF ENDLN OPEN METHOD BLOCKEND EQ INPUT DIV MUL MINUS PLUS LPAREN RPAREN FUNC RUN COMMA NEQ GREAT LESS RETURN ALGEBRA ALC COMMENT RETURN_TYPE IN WHILE RET BREAK LAMBDA GE LE ASSERT")

func Token(row_, column_, kind, data) {
    func as_tuple() {
        return tuple(row_, column_, kind, data)
    }
};

func Lexer(src) {
    var src = array();
    var idx = 0;
    var row = 1;
    var column = 1;

    | Implement dd as a builtin |;
    var kws = dd(TokenKind.IDENT);
    update(kws, "print", TokenKind.PRINT);
    update(kws, "var", TokenKind.VAR);
    update(kws, "if", TokenKind.IF);
    update(kws, "=", TokenKind.ASSIGN);
    update(kws, "{", TokenKind.THEN);
    update(kws, "else", TokenKind.ELSE);
    update(kws, "}", TokenKind.BLOCKEND);
    update(kws, "return", TokenKind.RETURN);
    update(kws, "(", TokenKind.LPAREN);
    update(kws, ")", TokenKind.RPAREN);
    update(kws, ";", TokenKind.ENDLN);
    update(kws, "is", TokenKind.EQ);
    update(kws, "not", TokenKind.NEQ);
    update(kws, "*", TokenKind.MUL);
    update(kws, "/", TokenKind.DIV);
    update(kws, "-", TokenKind.MINUS);
    update(kws, "+", TokenKind.PLUS);
    update(kws, ">", TokenKind.GREAT);
    update(kws, "<", TokenKind.LESS);
    update(kws, ",", TokenKind.COMMA);
    update(kws, "input", TokenKind.INPUT);
    update(kws, "import", TokenKind.RUN);
    update(kws, "sio", TokenKind.RUN);
    update(kws, ":", TokenKind.RETURN_TYPE);
    update(kws, "in", TokenKind.IN);
    update(kws, "while", TokenKind.WHILE);
    update(kws, "ret", TokenKind.RET);
    update(kws, "break", TokenKind.BREAK);
    update(kws, "print", TokenKind.PRINT);
    update(kws, "ge", TokenKind.GE);
    update(kws, "le", TokenKind.LE);
    update(kws, "assert", TokenKind,ASSERT);

    func lex_num() {
        var match = "";
        while idx < len(src) {
            while isdigit(grab(src, idx)) {
                var match = match + grab(src, idx);
                eat()
            }
        };
        return Token(row, column, INT, int(match))
    };

    func current_char_is_valid_in_an_identifier() {
            var current = grab(src, idx);
            return is_identifier(current) or current is "."
    };

    func lex_ident() {
        var match_ = "";
        while idx < len(src) {
            while current_char_is_valid_in_an_identifier() {
                var match_ = match_ + grab(src, idx);
                eat()
            }
        };

        var kind = grab(kws, match_);
        return Token(row, column, kind, match)
    };

    func consume_whitespace() {
        while idx < len(src) {
            while is_space(grab(src, idx)) {
                eat()
            }
        }
    };

    func __next__() {
        if idx ge len(src) {
            exit()
        };
        consume_whitespace();
        var ch = grab(src, idx);
        if is_alpha(ch) {
            return lex_ident()
        }
        else {
            if isdigit(ch) {
                return lex_num()
            }
            else {
                | Make it so that this accepts ' as a valid char |;
                if ch is '"' {
                    return lex_string_literal()
                }
                else {
                    if ch is "|" {
                        return lex_comment()
                    }
                    else {
                        eat();
                        if grab(kws, ch) is TokenKind.IDENT {
                            update(kws, ch, TokenKind.UNKNOWN)
                        };
                        var kind_ = grab(kws, ch);
                        return Token(row, column, kind_, ch)
                    }
                }
            }
        }
    };

    func lex_string_literal() {
        assert {grab(src, idx) is '"'};
        eat();
    
        var literal = "";
        while idx < len(src) {
            while grab(src, idx) not '"' {
                var literal = grab(src, idx);
                eat()
            }
        };
            
        if idx ge len(src) {
            print "Missing end of string delimiter!";
            return Token(row, column, TokenKind.UNKNOWN, literal)
        };

        assert {grab(src, idx) is '"'};
        eat();
        return Token(row, column, TokenKind.STRING, literal)
    };

    func lex_comment() {
        assert {grab(src, idx) is '|'};
        eat();

        var comment = "";
        while idx < len(src) {
            while grab(src, idx) not '|' {
                var comment = grab(src, idx);
                eat()
            }
        };

        if idx ge len(src) {
            print "Missing end of comment; |; or just | at end of file";
            return Token(row, column, TokenKind.UNKNOWN, comment)
        };

        assert {grab(src, idx) is '|'};
        eat();
        return Token(row, column, TokenKind.STRING, comment)
    };

    func eat() {
        if grab(src, idx) is "\n" {
            var row = row + 1;
            var column = 1
        }
        else {
            var column = column + 1
        };
        var idx = idx + 1
    }
};

|
TODO:
1. AST Nodes
2. Parser
3. Shitter
4. Binary
|;

func Parser() {
    return 0
}
